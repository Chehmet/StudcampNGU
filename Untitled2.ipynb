{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Генерация данных\n",
        "def generate_data(pe, n_samples):\n",
        "    x_inv = np.random.randn(n_samples, 2)\n",
        "    Y = x_inv.sum(axis=1, keepdims=True) + 0.1 * np.random.randn(n_samples, 1)\n",
        "    x_env = np.column_stack([Y.squeeze(), Y.squeeze()]) + np.sqrt(pe) * np.random.randn(n_samples, 2)\n",
        "    X = np.hstack([x_inv, x_env])\n",
        "    return X, Y\n",
        "\n",
        "# Создание DataLoader\n",
        "def create_dataloader(pe, count, batch_size):\n",
        "    res_X, res_Y = [], []\n",
        "    for p in pe:\n",
        "        X, Y = generate_data(p, count)\n",
        "        res_X.append(X)\n",
        "        res_Y.append(Y)\n",
        "    # Используем vstack вместо устаревшего row_stack\n",
        "    res_X = np.vstack(res_X)\n",
        "    res_Y = np.vstack(res_Y)\n",
        "    dataset = TensorDataset(torch.tensor(res_X, dtype=torch.float32),\n",
        "                          torch.tensor(res_Y, dtype=torch.float32))\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "qw2Gog1w2ARN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Параметры данных\n",
        "pe_train = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "pe_val = [0.4, 0.8]\n",
        "pe_test = [10.0, 100.0]\n",
        "count = 2000\n",
        "batch_size = 16\n",
        "\n",
        "np.random.seed(50)\n",
        "torch.manual_seed(50)\n",
        "\n",
        "# Создаем загрузчики данных\n",
        "train_loader = create_dataloader(pe_train, count, batch_size)\n",
        "val_loader = create_dataloader(pe_val, count, batch_size)\n",
        "test_loader = create_dataloader(pe_test, count, batch_size)"
      ],
      "metadata": {
        "id": "W6R_xrfE2BMp"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Модель для регрессии\n",
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(4, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 8),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Функции для оценки\n",
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    mse_loss = 0\n",
        "    mae_loss = 0\n",
        "    criterion_mse = nn.MSELoss()\n",
        "    criterion_mae = nn.L1Loss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, Y in dataloader:\n",
        "            outputs = model(X)\n",
        "            mse_loss += criterion_mse(outputs, Y).item()\n",
        "            mae_loss += criterion_mae(outputs, Y).item()\n",
        "\n",
        "    return mse_loss/len(dataloader), mae_loss/len(dataloader)"
      ],
      "metadata": {
        "id": "7Xvw3cGiwnx1"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение ансамбля\n",
        "def train_ensemble(train_loader, val_loader, pe_list, n_epochs=100):\n",
        "    ensemble = []\n",
        "\n",
        "    for i, excluded_pe in enumerate(pe_list):\n",
        "        print(f\"\\nTraining model {i+1}, excluding pe={excluded_pe}\")\n",
        "\n",
        "        # Создаем подмножество данных без excluded_pe\n",
        "        all_X, all_Y = [], []\n",
        "        for X, Y in train_loader:\n",
        "            all_X.append(X)\n",
        "            all_Y.append(Y)\n",
        "        all_X = torch.cat(all_X)\n",
        "        all_Y = torch.cat(all_Y)\n",
        "\n",
        "        # Разделяем данные по pe (предполагаем упорядоченность)\n",
        "        samples_per_pe = len(all_X) // len(pe_list)\n",
        "        mask = torch.ones(len(all_X), dtype=bool)\n",
        "        start_idx = i * samples_per_pe\n",
        "        end_idx = start_idx + samples_per_pe\n",
        "        mask[start_idx:end_idx] = False\n",
        "\n",
        "        partial_dataset = TensorDataset(all_X[mask], all_Y[mask])\n",
        "        partial_loader = DataLoader(partial_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        # Инициализация и обучение модели\n",
        "        model = RegressionModel()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        for epoch in range(n_epochs):\n",
        "            model.train()\n",
        "            epoch_loss = 0\n",
        "            for X_batch, Y_batch in partial_loader:\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(X_batch)\n",
        "                loss = criterion(outputs, Y_batch)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "            # Валидация\n",
        "            val_mse, val_mae = evaluate_model(model, val_loader)\n",
        "            if (epoch % 7 == 0 or epoch == n_epochs - 1):\n",
        "              print(f\"Epoch {epoch+1}/{n_epochs} | Train Loss: {epoch_loss/len(partial_loader):.4f} | Val MSE: {val_mse:.4f} | Val MAE: {val_mae:.4f}\")\n",
        "\n",
        "        ensemble.append(model)\n",
        "\n",
        "    return ensemble"
      ],
      "metadata": {
        "id": "z00hPYgn19Sc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение ансамбля из 5 моделей\n",
        "ensemble = train_ensemble(train_loader, val_loader, pe_train, n_epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIdkotY72-y0",
        "outputId": "56ecee39-de54-42f8-c07d-d5dbe8d96964"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training model 1, excluding pe=0.1\n",
            "Epoch 1/20 | Train Loss: 0.4676 | Val MSE: 0.0663 | Val MAE: 0.1993\n",
            "Epoch 8/20 | Train Loss: 0.0103 | Val MSE: 0.0123 | Val MAE: 0.0885\n",
            "Epoch 15/20 | Train Loss: 0.0104 | Val MSE: 0.0114 | Val MAE: 0.0853\n",
            "Epoch 20/20 | Train Loss: 0.0100 | Val MSE: 0.0104 | Val MAE: 0.0816\n",
            "\n",
            "Training model 2, excluding pe=0.3\n",
            "Epoch 1/20 | Train Loss: 0.9358 | Val MSE: 0.6200 | Val MAE: 0.5072\n",
            "Epoch 8/20 | Train Loss: 0.0614 | Val MSE: 0.0508 | Val MAE: 0.1185\n",
            "Epoch 15/20 | Train Loss: 0.0192 | Val MSE: 0.0178 | Val MAE: 0.0884\n",
            "Epoch 20/20 | Train Loss: 0.0141 | Val MSE: 0.0137 | Val MAE: 0.0848\n",
            "\n",
            "Training model 3, excluding pe=0.5\n",
            "Epoch 1/20 | Train Loss: 0.3603 | Val MSE: 0.0296 | Val MAE: 0.1338\n",
            "Epoch 8/20 | Train Loss: 0.0101 | Val MSE: 0.0109 | Val MAE: 0.0833\n",
            "Epoch 15/20 | Train Loss: 0.0100 | Val MSE: 0.0116 | Val MAE: 0.0856\n",
            "Epoch 20/20 | Train Loss: 0.0099 | Val MSE: 0.0105 | Val MAE: 0.0814\n",
            "\n",
            "Training model 4, excluding pe=0.7\n",
            "Epoch 1/20 | Train Loss: 0.4862 | Val MSE: 0.0359 | Val MAE: 0.1470\n",
            "Epoch 8/20 | Train Loss: 0.0103 | Val MSE: 0.0105 | Val MAE: 0.0814\n",
            "Epoch 15/20 | Train Loss: 0.0101 | Val MSE: 0.0104 | Val MAE: 0.0814\n",
            "Epoch 20/20 | Train Loss: 0.0100 | Val MSE: 0.0102 | Val MAE: 0.0807\n",
            "\n",
            "Training model 5, excluding pe=0.9\n",
            "Epoch 1/20 | Train Loss: 0.4975 | Val MSE: 0.0689 | Val MAE: 0.2089\n",
            "Epoch 8/20 | Train Loss: 0.0103 | Val MSE: 0.0106 | Val MAE: 0.0816\n",
            "Epoch 15/20 | Train Loss: 0.0099 | Val MSE: 0.0108 | Val MAE: 0.0827\n",
            "Epoch 20/20 | Train Loss: 0.0098 | Val MSE: 0.0108 | Val MAE: 0.0829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Оценка ансамбля на тестовых данных\n",
        "def evaluate_ensemble(ensemble, test_loader):\n",
        "    ensemble_mse = 0\n",
        "    ensemble_mae = 0\n",
        "    criterion_mse = nn.MSELoss()\n",
        "    criterion_mae = nn.L1Loss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, Y in test_loader:\n",
        "            # Усредняем предсказания всех моделей\n",
        "            predictions = torch.stack([model(X) for model in ensemble]).mean(dim=0)\n",
        "            ensemble_mse += criterion_mse(predictions, Y).item()\n",
        "            ensemble_mae += criterion_mae(predictions, Y).item()\n",
        "\n",
        "    return ensemble_mse/len(test_loader), ensemble_mae/len(test_loader)\n",
        "\n",
        "test_mse, test_mae = evaluate_ensemble(ensemble, test_loader)\n",
        "print(f\"\\nFinal Ensemble Test Metrics: MSE = {test_mse:.4f}, MAE = {test_mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dso56_pw2lJb",
        "outputId": "7d2aa60c-7c87-49a7-f6f7-5f0655cf21f1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Ensemble Test Metrics: MSE = 0.7947, MAE = 0.5285\n"
          ]
        }
      ]
    }
  ]
}