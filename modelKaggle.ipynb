{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12540295,"sourceType":"datasetVersion","datasetId":7916908},{"sourceId":12543667,"sourceType":"datasetVersion","datasetId":7919379}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\nfrom tqdm.auto import tqdm ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-22T11:10:25.325981Z","iopub.execute_input":"2025-07-22T11:10:25.326579Z","iopub.status.idle":"2025-07-22T11:10:26.282487Z","shell.execute_reply.started":"2025-07-22T11:10:25.326532Z","shell.execute_reply":"2025-07-22T11:10:26.281618Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import ast  # Импортируем модуль для безопасного парсинга строк\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification\nfrom tqdm.auto import tqdm\n\n# --- КОНФИГУРАЦИЯ ---\nmodel_name = \"iiiorg/piiranha-v1-detect-personal-information\"\n# ИЗМЕНЕНИЕ 1: Указываем путь к вашему CSV файлу. \n# Я предполагаю, что вы сохраните ваш пример как 'my_log_data.csv'\n# Важно, чтобы это был CSV, а не JSONL, судя по формату.\ndata_file = \"/kaggle/input/proc-s-csv/processed_synthetic_dataset.csv\" \ntokenized_dataset_path = \"./tokenized_log_dataset\"\n\n# --- ЗАГРУЗКА ---\nprint(\"--- Шаг 1: Загрузка токенизатора и предварительная обработка датасета ---\")\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# ИЗМЕНЕНИЕ 2: Загружаем данные как CSV\nprint(f\"Загружаю CSV файл: {data_file}\")\nfull_dataset = load_dataset(\"csv\", data_files=data_file, split=\"train\")\nprint(\"Датасет загружен. Всего записей:\", len(full_dataset))\n\n\n# ИЗМЕНЕНИЕ 3: Предобработка данных для приведения к нужному формату\ndef prepare_dataset(examples):\n    # Колонки 'mbert_tokens' и 'mbert_token_classes' - это строки.\n    # Превращаем их в реальные списки Python.\n    # ast.literal_eval безопасно выполняет эту операцию.\n    examples[\"tokens\"] = [ast.literal_eval(tok_list) for tok_list in examples[\"mbert_tokens\"]]\n    examples[\"ner_labels\"] = [ast.literal_eval(label_list) for label_list in examples[\"mbert_token_classes\"]]\n    return examples\n\nprint(\"\\n--- Шаг 2: Преобразование строковых колонок в списки ---\")\n# Применяем нашу функцию ко всему датасету\n# Удаляем старые и ненужные колонки, чтобы сэкономить память\ncolumns_to_remove = [col for col in full_dataset.column_names if col not in ['mbert_tokens', 'mbert_token_classes']]\nprepared_dataset = full_dataset.map(\n    prepare_dataset,\n    batched=True,\n    num_proc=2,\n    remove_columns=columns_to_remove,\n    desc=\"Парсинг токенов и меток\"\n)\nprint(\"Преобразование завершено.\")\n\n\n# --- Получение меток из модели ---\nmodel_config = AutoModelForTokenClassification.from_pretrained(model_name).config\nid2label = {int(k): v for k, v in model_config.id2label.items()}\nlabel2id = {v: k for k, v in id2label.items()}\nprint(\"\\nСловарь меток (label2id) из модели:\", label2id)\n\n\n# --- ФУНКЦИЯ ТОКЕНИЗАЦИИ (остается без изменений) ---\ndef tokenize_and_align_labels(examples):\n    # Теперь эта функция получит на вход колонки 'tokens' и 'ner_labels', как и ожидала\n    tokenized_inputs = tokenizer(\n        examples[\"tokens\"],\n        truncation=True,\n        is_split_into_words=True,\n        max_length=512,\n    )\n    all_labels = []\n    for i, ner_tags in enumerate(examples[\"ner_labels\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                tag = ner_tags[word_idx]\n                # Важно: если в вашем датасете есть метка, которой нет в модели, ставим 'O'\n                label_ids.append(label2id.get(tag, label2id[\"O\"]))\n            else:\n                label_ids.append(-100)\n            previous_word_idx = word_idx\n        all_labels.append(label_ids)\n    tokenized_inputs[\"labels\"] = all_labels\n    return tokenized_inputs\n\n# --- ОБРАБОТКА И СОХРАНЕНИЕ ---\nprint(\"\\n--- Шаг 3: Начинаю токенизацию данных (прогресс-бар появится ниже) ---\")\n# ИЗМЕНЕНИЕ 4: Применяем токенизацию к нашему новому `prepared_dataset`\ntokenized_datasets = prepared_dataset.map(\n    tokenize_and_align_labels,\n    batched=True,\n    num_proc=2,\n    remove_columns=prepared_dataset.column_names, # Удаляем старые колонки\n    desc=\"Токенизация логов\"\n)\nprint(\"Токенизация завершена.\")\n\n\nprint(f\"\\n--- Шаг 4: Сохраняю обработанный датасет в '{tokenized_dataset_path}' ---\")\ntokenized_datasets.save_to_disk(tokenized_dataset_path)\nprint(\"Подготовка данных успешно завершена!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T11:10:28.269884Z","iopub.execute_input":"2025-07-22T11:10:28.270767Z","iopub.status.idle":"2025-07-22T11:11:01.811167Z","shell.execute_reply.started":"2025-07-22T11:10:28.270739Z","shell.execute_reply":"2025-07-22T11:11:01.810414Z"}},"outputs":[{"name":"stdout","text":"--- Шаг 1: Загрузка токенизатора и предварительная обработка датасета ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20c9a1c2bba649bfa7f338a28bb9de68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c092020d12f4deeb7151cb10aa540d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/16.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3d2af7cca2a4ed3a055089e6059c1ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c057a3d9e3449c9aa3eea7a557cc37b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a64d98c11394cadbabbe1c61ddc3ea7"}},"metadata":{}},{"name":"stdout","text":"Загружаю CSV файл: /kaggle/input/proc-s-csv/processed_synthetic_dataset.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b275d7592e24959bec44d5cb04443fd"}},"metadata":{}},{"name":"stdout","text":"Датасет загружен. Всего записей: 800\n\n--- Шаг 2: Преобразование строковых колонок в списки ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Парсинг токенов и меток (num_proc=2):   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb34d7a38d2a434898847b4eee9991c0"}},"metadata":{}},{"name":"stdout","text":"Преобразование завершено.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7c948bbdd3c497dac1d577e3cc3bd0f"}},"metadata":{}},{"name":"stderr","text":"2025-07-22 11:10:40.222173: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753182640.604109      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753182640.713197      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04fe5a7d0d964f559864d2affd3899ee"}},"metadata":{}},{"name":"stdout","text":"\nСловарь меток (label2id) из модели: {'I-ACCOUNTNUM': 0, 'I-BUILDINGNUM': 1, 'I-CITY': 2, 'I-CREDITCARDNUMBER': 3, 'I-DATEOFBIRTH': 4, 'I-DRIVERLICENSENUM': 5, 'I-EMAIL': 6, 'I-GIVENNAME': 7, 'I-IDCARDNUM': 8, 'I-PASSWORD': 9, 'I-SOCIALNUM': 10, 'I-STREET': 11, 'I-SURNAME': 12, 'I-TAXNUM': 13, 'I-TELEPHONENUM': 14, 'I-USERNAME': 15, 'I-ZIPCODE': 16, 'O': 17}\n\n--- Шаг 3: Начинаю токенизацию данных (прогресс-бар появится ниже) ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Токенизация логов (num_proc=2):   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bae2242eeec642e0be91eea7213a4b1c"}},"metadata":{}},{"name":"stdout","text":"Токенизация завершена.\n\n--- Шаг 4: Сохраняю обработанный датасет в './tokenized_log_dataset' ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a7066946c444ec8829c56501383120c"}},"metadata":{}},{"name":"stdout","text":"Подготовка данных успешно завершена!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install seqeval\n!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T11:11:14.305829Z","iopub.execute_input":"2025-07-22T11:11:14.306054Z","iopub.status.idle":"2025-07-22T11:11:21.391971Z","shell.execute_reply.started":"2025-07-22T11:11:14.306016Z","shell.execute_reply":"2025-07-22T11:11:21.391209Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: seqeval in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.2.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.14.0->seqeval) (2.4.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.14.0->seqeval) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->seqeval) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.14.0->seqeval) (2024.2.0)\nRequirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.5)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# import transformers\n# print(transformers.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T05:56:33.558446Z","iopub.execute_input":"2025-07-22T05:56:33.558685Z","iopub.status.idle":"2025-07-22T05:56:33.562714Z","shell.execute_reply.started":"2025-07-22T05:56:33.558652Z","shell.execute_reply":"2025-07-22T05:56:33.561849Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# !pip install --upgrade --force-reinstall \"numpy<2\" \"datasets\" \"transformers\" \"torch\" \"evaluate\" \"seqeval\" \"scikit-learn\" \"tqdm\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T05:56:33.564448Z","iopub.execute_input":"2025-07-22T05:56:33.564647Z","iopub.status.idle":"2025-07-22T05:56:33.581015Z","shell.execute_reply.started":"2025-07-22T05:56:33.564632Z","shell.execute_reply":"2025-07-22T05:56:33.580302Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from datasets import load_from_disk\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForTokenClassification,\n    TrainingArguments,\n    Trainer,\n    DataCollatorForTokenClassification,\n    pipeline  # <-- ИЗМЕНЕНИЕ 1: Импортируем pipeline для удобного предсказания\n)\nimport evaluate\nimport numpy as np\nimport pandas as pd # <-- ИЗМЕНЕНИЕ 2: Импортируем pandas для красивого вывода\nfrom tqdm.auto import tqdm\n\n# --- КОНФИГУРАЦИЯ ---\nmodel_name = \"iiiorg/piiranha-v1-detect-personal-information\"\ntokenized_dataset_path = \"./tokenized_log_dataset\"\noutput_dir = \"piiranha-finetuned-logs\"\nfinal_model_path = f\"{output_dir}-final\"\n\n# --- ЗАГРУЗКА ---\nprint(\"Загружаю подготовленный датасет...\")\ntokenized_datasets_from_disk = load_from_disk(tokenized_dataset_path)\ndataset_dict = tokenized_datasets_from_disk.train_test_split(test_size=0.1, seed=42) # Добавим seed для воспроизводимости\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForTokenClassification.from_pretrained(model_name)\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n\n# --- МЕТРИКИ (ОБНОВЛЕННАЯ ВЕРСИЯ) ---\nseqeval = evaluate.load(\"seqeval\")\nlabel_list = list(model.config.id2label.values())\n\n# ИЗМЕНЕНИЕ 3: Расширяем функцию метрик для детального отчета\ndef compute_metrics(p):\n    predictions, labels = p\n    predictions = np.argmax(predictions, axis=2)\n    true_predictions = [\n        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    true_labels = [\n        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    \n    # Получаем полный отчет от seqeval\n    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n    \n    # Собираем метрики по каждому классу PII\n    per_class_results = {}\n    for key, value in results.items():\n        if isinstance(value, dict) and 'f1-score' in value:\n             per_class_results[f\"{key}_precision\"] = value['precision']\n             per_class_results[f\"{key}_recall\"] = value['recall']\n             per_class_results[f\"{key}_f1\"] = value['f1-score']\n\n    return {\n        \"precision\": results[\"overall_precision\"],\n        \"recall\": results[\"overall_recall\"],\n        \"f1\": results[\"overall_f1\"],\n        \"accuracy\": results[\"overall_accuracy\"],\n        **per_class_results # Добавляем метрики по классам\n    }\n\n# --- НАСТРОЙКИ ОБУЧЕНИЯ ---\ntraining_args = TrainingArguments(\n    output_dir=output_dir,\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3, # Возможно, стоит увеличить до 5-10, раз модель не учится\n    weight_decay=0.01,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    logging_steps=10,\n    report_to=\"none\",\n)\n\n# --- ОБУЧЕНИЕ ---\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset_dict[\"train\"],\n    eval_dataset=dataset_dict[\"test\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\nprint(\"Начинаю дообучение модели...\")\ntrainer.train()\n\n# --- СОХРАНЕНИЕ ---\ntrainer.save_model(final_model_path)\nprint(f\"\\nОбучение завершено. Модель сохранена в '{final_model_path}'\")\n\n# --- ИЗМЕНЕНИЕ 4: ФУНКЦИЯ ДЛЯ ПРОСМОТРА ПРЕДСКАЗАНИЙ ---\ndef show_predictions(model_path, num_examples=3):\n    \"\"\"Загружает модель и показывает ее предсказания на нескольких примерах из тестового сета.\"\"\"\n    print(\"\\n--- Анализ предсказаний модели ---\")\n    \n    # Загружаем лучшую сохраненную модель\n    ner_pipe = pipeline(\"token-classification\", model=model_path, aggregation_strategy=\"simple\")\n    \n    test_set = dataset_dict[\"test\"]\n    \n    for i in range(num_examples):\n        if i >= len(test_set):\n            break\n        \n        example = test_set[i]\n        tokens = tokenizer.convert_ids_to_tokens(example['input_ids'])\n        true_labels = [label_list[l] if l != -100 else \"PAD\" for l in example['labels']]\n        \n        # Склеиваем токены обратно в текст для pipeline\n        text = tokenizer.decode(example['input_ids'], skip_special_tokens=True)\n        \n        print(f\"\\n--- Пример #{i+1} ---\")\n        print(f\"Текст: {text}\")\n        \n        predictions = ner_pipe(text)\n        \n        # Создаем словарь предсказаний для удобства\n        pred_map = {}\n        for pred in predictions:\n            # Pipeline может склеивать B- и I- токены. Нам нужно найти начальный токен.\n            start_token_index = tokenizer(pred['word'], add_special_tokens=False).input_ids[0]\n            for tok_idx in tokenizer(pred['word'], add_special_tokens=False).input_ids:\n                 pred_map[tok_idx] = pred['entity_group']\n\n        # Создаем DataFrame для наглядного сравнения\n        results_df = pd.DataFrame({\n            \"Токен\": tokens,\n            \"Настоящая метка\": true_labels\n        })\n        \n        # Добавляем предсказания, если они есть\n        predicted_labels = []\n        for j, token_id in enumerate(example['input_ids']):\n            if true_labels[j] == \"PAD\": # Пропускаем паддинг\n                continue\n            \n            # Находим предсказание для этого токена\n            # ВАЖНО: этот метод не идеален, т.к. pipeline агрегирует токены,\n            # но для визуальной проверки он хорошо подходит.\n            # Более точный способ требует ручного прогона модели и сопоставления.\n            # Сейчас для простоты оставим так.\n            \n            # Более простой и надежный способ: прогоним токенизированный ввод через модель\n        \n    # Более точный способ без pipeline\n    print(\"\\n--- Точный анализ предсказаний (без pipeline) ---\")\n    model.eval()\n    for i in range(num_examples):\n        example = test_set[i]\n        input_ids = torch.tensor(example['input_ids']).unsqueeze(0).to(model.device)\n        \n        with torch.no_grad():\n            logits = model(input_ids).logits\n        \n        predictions = torch.argmax(logits, dim=2).squeeze().tolist()\n        \n        tokens = tokenizer.convert_ids_to_tokens(example['input_ids'])\n        true_labels = [label_list[l] if l != -100 else \"PAD\" for l in example['labels']]\n        pred_labels = [label_list[p] for p in predictions]\n        \n        df = pd.DataFrame({\n            'Токен': tokens, \n            'Реальная метка': true_labels, \n            'Предсказание модели': pred_labels\n        })\n        \n        # Фильтруем PAD и спец.токены для чистоты вывода\n        df_filtered = df[(df['Реальная метка'] != 'PAD') & (~df['Токен'].isin(['[CLS]', '[SEP]', '[PAD]']))]\n        \n        print(f\"\\n--- Пример #{i+1} ---\")\n        \n        # Выводим только строки, где есть расхождения или где есть PII\n        mismatches = df_filtered[df_filtered['Реальная метка'] != df_filtered['Предсказание модели']]\n        real_pii = df_filtered[df_filtered['Реальная метка'] != 'O']\n        \n        display_df = pd.concat([real_pii, mismatches]).drop_duplicates().sort_index()\n\n        if display_df.empty:\n            print(\"Расхождений не найдено, и в примере нет PII.\")\n        else:\n            print(display_df.to_string())\n\n# Запускаем нашу новую функцию\nimport torch # Нужно для точного анализа\nshow_predictions(final_model_path, num_examples=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T11:16:46.881918Z","iopub.execute_input":"2025-07-22T11:16:46.882598Z","iopub.status.idle":"2025-07-22T11:20:38.384267Z","shell.execute_reply.started":"2025-07-22T11:16:46.882572Z","shell.execute_reply":"2025-07-22T11:20:38.383391Z"}},"outputs":[{"name":"stdout","text":"Загружаю подготовленный датасет...\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_36/1118594090.py:82: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"name":"stdout","text":"Начинаю дообучение модели...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [135/135 03:41, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.104000</td>\n      <td>0.116968</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.983367</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.092400</td>\n      <td>0.112619</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.982232</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.094300</td>\n      <td>0.112595</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.982824</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"\nОбучение завершено. Модель сохранена в 'piiranha-finetuned-logs-final'\n\n--- Анализ предсказаний модели ---\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cuda:0\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"name":"stdout","text":"\n--- Пример #1 ---\nТекст: < log >< action > login </ action >< timestamp > 2025 -07-15 T 0 6:26 :46.554 099 </ timestamp >< login > dun n kevin </ login >< given Name > Andre C arpenter </ given Name >< contact Number > 001 - 947 -400 - 4480 x 584 78 </ contact Number >< client _ ip > 4.1.1 13. 6 </ client _ ip ></ log > < log >< timestamp > 2025 -07-15 T 0 6:29 :48.554 099 </ timestamp >< client _ ip > 207. 6.75.103 </ client _ ip >< contact Number > 98 1478 3125 </ contact Number >< action > search </ action >< financial Account > GB 12 X VES 995 1833 2946 970 </ financial Account >< account Name > johnson dar ry l </ account Name ></ log > < log >< handle > u anderson </ handle >< action > update </ action >< client _ ip > 184. 116. 1 1.81 </ client _ ip >< timestamp > 2025 -07-15 T 06 :3 1:02.554 099 </ timestamp ></ log > < log >< login > dawn marks </ login >< client _ ip > 100. 226.96. 152 </ client _ ip >< action > purchase </ action >< pass Key > ( Q d 7 ACP i w # 41 </ pass Key >< timestamp > 2025 -07-15 T 0 6:32 :17.554 099 </ timestamp >< card Num > 540 3129 7375 7022 5 </ card\n\n--- Пример #2 ---\nТекст: account Code, account Name, account No, action, b illing _ address, client _ ip, contact Mail, contact Name, delivery Address, home _ address, login, message, mobile Phone, pass Key, pass phrase, person Name, secret Code, secret _ key, social _ security, s s Number, street, tax _ id, telephone, timestamp, user Mail, user _ id, username , l strick land, GB 11 G RBI 079 03 1544 7 6137, update,, 17 6.4 3.21 0.18,,,,,,,,, I 5% L 4 V vq GE ^2,,,,,,,,, 2025 -03-25 T 1 6:46 :36.63 4088,,, ,,, update,, 89. 74.191.55, jerem iah white @ example. com,,,, david weave r,,,,,,,,,, \" 3 772 A llison Trail, Green e side, IN 57 971 \",,, 2025 -03-25 T 16:51 :29.63 4088,,, , d long,, logo ut,\" 10 158 David Rue,  Werner bury, UT 29 831 \", 12. 174. 65. 170,, David Moore,,,,,,,,,,,,,,,, 2025 -03-25 T 16:55 :09.63 4088,,, GB 05 US CU 375 833 924 2229 4,,, search,, 130. 229.66.51,,,,,,,,,,,,,, 067 -29 - 1445,,,,\n\n--- Пример #3 ---\nТекст: action : logo ut |  timestamp : 2025 -07-08 T 16:03 :1 7.23 2060 | bank Code : GB 90 GN ZI 417 2986 420 7108 | client _ ip : 17 2.47. 200. 155 | account Name : con ley pedro action : logo ut | client _ ip : 14 3.13 3.5 2.79 |  displayName : Mark Wilson |  timestamp : 2025 -07-08 T 16:07 :4 1.23 2060 | bank Card : 630 4119 08 944 | handle : mark 12 message : 205. 185. 116. 89  -  - [16 / Jul /20 21:06 :3 5:07 + 0900 ] \" GET  / ajax / lib s / jquery / 3.4. 1/ jquery. min. js HTTP /1.1 \" 404 45 15 \" http :// i 114- 188 -106 -2. s 42. a 026. ap. p lala. or. jp / \" \" Mozilla / 5.0 ( Macintosh ; Intel Mac OS X 11 _0_ 0) Apple Web Kit /53 7.36 ( K HTML, like G ecko ) Chrome /87. 0.42 8 0.88 Safari /53 7.36 \" login :  a aron william s |  timestamp : 2025 -07-08 T 16:10 :2 6.23 2060 | client _ ip : 20. 225.235. 190 | action : purchase  username : her na ndez michael | client _ ip : 18 9.8 7.25 0.2 | login Pass :  _1 AH ur + x % # tv |\n\n--- Пример #4 ---\nТекст: action : purchase |  timestamp : 2025 -07-14 T 00:22 :36.44 7555 |  username : gav in 30 | client _ ip : 25. 214. 89. 175  timestamp : 2025 -07-14 T 00 :2 6:06.44 7555 | user _ id : ag u ir re alex | client _ ip : 5. 139. 194.56 | action : login account Name :  erika mur phy | client _ ip : 12 3.15 3.19 2.35 |  timestamp : 2025 -07-14 T 00 :32 :0 2.44 7555 | action : update | card _ number : 35 9876 7717 482 794  timestamp : 2025 -07-14 T 00 :32 :35.44 7555 | client _ ip : 17 6.16 2.3 3.24 | message : Interest ing live economic such loss past  newspaper write. 3.2 2.75.131  -  - [ 26/ Sep / 202 3:08 : 14:28 + 0900 ] \" GET // cdn js. cloud flare. com / ajax / lib s / fuse. js / 3.2.1 / fuse. min. js HTTP /1.1 \" 404 46 11 \" - \" \" Mozilla / 5.0 ( X 11 ; Linux  x 86_64 ;  r v : 19.0 ) G ecko /2010 0101 Firefox / 19.0 Ice we a sel /19.0.2 \" |  username : lauren tor res | pass :  n wv DN 8 Oc ^ 5 CT | action : purchase client _ ip : 2\n\n--- Пример #5 ---\nТекст:  timestamp : 2025 -06-11 T 22:26 :2 2.93 9785 |  s s n : 485 -87 - 2310 | action : update | user _ id : ma dison c line | client _ ip : 24. 184. 34. 205  timestamp : 2025 -06-11 T 2 2:30 :3 2.93 9785 | bill ing _ address :  057 Amy Union s, Edward chester, AL 125 13 | action : login |  cc Info : 413 1178 2436 21 | mobile : 001 - 622 -48 5-8 493 |  username : v h iggins | client _ ip : 18 3.17 3.34. 115 login :  a brown | sur name : Max well Os born | action : login | street : 480 Henry Hills Apt.  046, Port Con nie haven, GU  979 10 | client _ ip : 16 2.16 4.16 5.3 6 | mobile Phone : +1 - 552 - 787 - 3750 |  timestamp : 2025 -06-11 T 22:35 :26. 93 9785  timestamp : 2025 -06-11 T 22:38 :1 0.93 9785 | credit Card Number : 4 8381 485 2080 1534 354 | action : login | user Tag : cole mann ancy | client _ ip : 140. 127.17 9.98  timestamp : 2025 -06-11 T 2 2:43 :47. 93 9785 | client _ ip : 37. 122. 222. 59 |  residence : 749 Krist y Trail, Brand y ville,\n\n--- Точный анализ предсказаний (без pipeline) ---\n\n--- Пример #1 ---\n   Токен Реальная метка Предсказание модели\n35  ▁dun     I-PASSWORD                   O\n61  ▁001   I-ACCOUNTNUM                   O\n62     ▁   I-ACCOUNTNUM                   O\n74  ▁584   I-ACCOUNTNUM                   O\n75   ▁78   I-ACCOUNTNUM                   O\n\n--- Пример #2 ---\n       Токен Реальная метка Предсказание модели\n21  ▁address    I-SOCIALNUM                   O\n\n--- Пример #3 ---\n      Токен Реальная метка Предсказание модели\n71       ▁|       I-STREET                   O\n72  ▁client       I-STREET                   O\n\n--- Пример #4 ---\nРасхождений не найдено, и в примере нет PII.\n\n--- Пример #5 ---\n   Токен Реальная метка Предсказание модели\n49     ▁   I-ACCOUNTNUM                   O\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-22T05:56:38.114585Z","iopub.status.idle":"2025-07-22T05:56:38.114963Z","shell.execute_reply.started":"2025-07-22T05:56:38.114774Z","shell.execute_reply":"2025-07-22T05:56:38.114791Z"}},"outputs":[],"execution_count":null}]}